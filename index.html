<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<!-- <html> -->
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://kit.fontawesome.com/a076d05399.js" crossorigin="anonymous"></script>
    <title>Hanshu Yan (严汉书)</title>
</head>

<body style="margin-left:150; margin-right:150; margin-top:10; padding:0">

    <div id="toptitle">
        <!-- <h1 style="padding-left: 50" lang="zh" >Hanshu YAN (严 汉书) <font size="-0"> (Pronouns: he/him/his)</font></h1> -->
        <font lang="zh" size="5"><b>Hanshu YAN (严 汉书)</b></font> <font size="-0"> (Pronouns: he/him/his)</font> &nbsp;&nbsp;&nbsp;&nbsp;
        <!-- <a href="index.html">Home</a> &nbsp;&nbsp;&nbsp;&nbsp; -->
        <i class="material-icons">school</i>&nbsp;<a href="https://scholar.google.com/citations?user=MG817V4AAAAJ&hl=zh-CN&authuser=1">Google Scholar</a> &nbsp;&nbsp;&nbsp;&nbsp;
        <i class="material-icons">description</i>&nbsp;<a href="assets/cv.pdf">CV</a> &nbsp;&nbsp;&nbsp;&nbsp;
    </div>

    <!-- <div style="text-align:center;">
        <font lang="zh" size="5">Hanshu YAN (严 汉书) </font> <font size="-0"> (Pronouns: he/him/his)</font>
        <a href="index.html">Home</a> &nbsp;&nbsp;&nbsp;&nbsp;
        <a href="assets/cv.pdf">CV</a> &nbsp;&nbsp;&nbsp;&nbsp;
    </div> -->

<table summary="Table for page layout." id="tlayout" class="center">
    <tr valign="top">
    <td id="layout-content" style="width:100%">
        <table class="imgtable">
        <tr>
        <td>
            <img class="img-responsive" onMouseOver="this.src='assets/hanshu.png';" onMouseOut="this.src='assets/hanshu.png';" src="assets/hanshu.png" width = "auto" height = "120px" /> &nbsp;&nbsp;&nbsp;&nbsp;
        </td>
        <td align="left">
            <p>Senior Research Scientist @ Rhymes.AI <br></p>
            <p>Ph.D in Machine Learning @ NUS <br></p>
            <p><i class="fa fa-envelope-o" aria-hidden="true"></i>:&nbsp;hanshu.yan@outlook.com <br></p>
        </td>
        </tr> 
        </table>

        <!-- Biography -->
        <div id="bio", style="margin:30 auto;" >
            <p>
                He obtained PhD from NUS in 2022 with a research focus on robust deep vision models and optimizers. 
                His current work focuses on multimodal generation and understanding. 
                He has led or co-led several relevant projects, including <a href="https://github.com/magic-research/magic-edit">MagicEdit</a> and <a href="https://github.com/magic-research/magic-avatar">MagicAvatar</a>  for video editing, 
                <a href="https://github.com/magic-research/piecewise-rectified-flow">PeRFlow</a> for diffusion acceleration,
                and <a href="https://github.com/HanshuYAN/AdjointDPM">AdjointDPM</a> for controllable generation.
                He was also involved in several large-scale video generation projects, including MagicVideo and <a href="https://github.com/rhymes-ai/Allegro">Allegro</a>. 
                He will be dedicated to developing efficient and powerful models for video generation and understanding.
            </p>
            Academic Service: reviewer for ICML, ICLR, NeurIPS, CVPR, ACM Multimedia, etc. <br>
        </div>

        <div style="margin:30 auto;" >
            <h2><a name="service"></a>Experiences</h2>
            <ul style="list-style-type: none">
                <table style="width:80%">
                    <tr>
                        <td style="width:35%">Senior Research Scientist</td> <td style="width:35%">Rhymes.AI, Singapore</td> <td style="width:30%">07/2024 - Present</td>
                    </tr>
                    <tr>
                        <td>Research Scientist</td> <td>ByteDance, Singapore</td> <td>07/2022 - 07/2024</td>
                    </tr>
                    <tr>
                        <td>Reserach Engineer</td> <td>NUS, Singapore</td> <td>07/2017 - 07/2018</td>
                    </tr>
                    </table>
            </ul>
        </div>

        <div style="margin:30 auto;" >
            <h2><a name="service"></a>Education</h2>
            <ul style="list-style-type: none">
                <table style="width: 80%">
                    <tr>
                        <td style="width:40%">Ph.D,&nbsp; Deep Learning</td> <td style="width:40%"> NUS </td> <td style="width:20%">2022</td>
                    </tr>
                    <tr>
                        <td>M.Sc,&nbsp; EE</td> <td> NUS </td> <td>2017</td>
                    </tr>
                    <tr>
                        <td>B.Eng, EE & Math </td> <td> BUAA </td> <td>2015</td>
                    </tr>
                    </table>
            </ul>
        </div>





        <!-- Publications -->
        <div id="papers"; style="margin:30 auto;" >
            <h2><a name="publications"></a>Selected Papers</h2> 
            (
            <i>
                * Equally contributed; 
                <mark class='c0'>^</mark>AIGC, 
                <mark class='c1'>^</mark>ML robustness, 
                <mark class='c2'>^</mark>Learning algorithms, 
            </i>
            )

            <table style="width: 100%; text-align:left">
            <tbody>
                <tr><td style="width:30%"><br></td><td style="width:65%"></td></tr>  <!-- define cell width -->

                <tr>
                    <td><img class="Image" src="assets/projects/2024_perflow.png" width = "90%" height = "auto" /> &nbsp;&nbsp;</td>
                    <td>
                        <mark class='c0'>^</mark> <a href="https://arxiv.org/abs/2405.07510">PeRFlow; Piecewise Rectified Flow as Universal Plug-and-Play Accelerator</a>. <br>
                        <u>Hanshu Yan</u>, Xingchao Liu, Jiachun Pan, Jun Hao Liew, Qiang Liu, Jiashi Feng <br>
                        <i>NeurIPS 2024</i> &nbsp; <i class="material-icons">home</i>[<a href="https://github.com/magic-research/piecewise-rectified-flow">Page</a>] <br>
                    </td>
                </tr>
                <tr><td><br></td></tr>
                
                <tr>
                    <td><img class="Image" src="assets/projects/2024_drag.png" width = "90%" height = "auto" /> &nbsp;&nbsp;</td>
                    <td>
                        <mark class='c0'>^</mark> <a href="https://arxiv.org/abs/2306.14435">DragDiffusion: Harnessing Diffusion Models for Interactive Point-based Image Editing</a>. <br>
                        Yujun Shi, Chuhui Xue, Jun Hao Liew, Jiachun Pan, <u>Hanshu Yan</u>, Wenqing Zhang, Vincent Y. F. Tan, Song Bai <br>
                        <i>CVPR 2024</i> &nbsp; <i class="material-icons">home</i>[<a href="https://github.com/Yujun-Shi/DragDiffusion">Page</a>] <br>
                        <mark class='c0'>^</mark> <a href="https://arxiv.org/abs/2405.13722">LightningDrag: Lightning Fast and Accurate Drag-based Image Editing Emerging from Videos</a>. <br>
                        Yujun Shi, Jun Hao Liew, <u>Hanshu Yan</u>, Vincent Y. F. Tan, Jiashi Feng <br>
                        <i>arXiv 2024</i> <br>
                    </td>
                </tr>
                <tr><td><br></td></tr>

                <tr>
                    <td><img class="Image" src="assets/projects/2024_magicvideo.png" width = "90%" height = "auto" /> &nbsp;&nbsp;</td>
                    <td>
                        <mark class='c0'>^</mark> <a href="https://arxiv.org/abs/2401.04468">MagicVideo-V2: Multi-Stage High-Aesthetic Video Generation</a>. <br>
                        Weimin Wang, Jiawei Liu, Zhijie Lin, Jiangqiao Yan, Shuo Chen, Chetwin Low, Tuyen Hoang, Jie Wu, Jun Hao Liew, <u>Hanshu Yan</u>, Daquan Zhou, Jiashi Feng <br>
                        <i>arXiv 2024</i> &nbsp; <i class="material-icons">home</i>[<a href="https://magicvideov2.github.io/">Page</a>] <br>
                        <mark class='c0'>^</mark> <a href="https://arxiv.org/abs/2211.11018">MagicVideo: Efficient Video Generation With Latent Diffusion Models</a>. <br> 
                        Daquan Zhou, Weimin Wang, <u>Hanshu Yan</u>, Weiwei Lv, Yizhe Zhu, Jiashi Feng <br>
                        <i>arXiv 2023</i> &nbsp; <i class="material-icons">home</i>[<a href="https://magicvideo.github.io">Page</a>] <br>
                    </td>
                </tr>
                <tr><td><br></td></tr>
                

                <tr>
                    <td><img class="Image" src="assets/projects/2023_magicedit.png" width = "90%" height = "auto" /> &nbsp;&nbsp;</td>
                    <td>
                        <mark class='c0'>^</mark> <a href="https://arxiv.org/abs/2308.14749">MagicEdit: High-Fidelity and Temporally Coherent Video Editing</a>.<br>
                        Jun Hao Liew*, <u>Hanshu Yan</u>*, Jianfeng Zhang, Zhongcong Xu, Jiashi Feng <br>
                        <i>arXiv 2023</i> &nbsp; <i class="material-icons">home</i>[<a href="https://github.com/magic-research/magic-edit">Page</a>] <br>
                        <mark class='c0'>^</mark> <a href="https://arxiv.org/abs/2308.14748">MagicAvatar: Multimodal Avatar Generation and Animation</a>. <br>
                        Jianfeng Zhang*, <u>Hanshu Yan</u>*, Zhongcong Xu*, Jiashi Feng, Jun Hao Liew* <br>
                        <i>arXiv 2023</i> &nbsp; <i class="material-icons">home</i>[<a href="https://magic-avatar.github.io/">Page</a>] <br>
                        <mark class='c0'>^</mark> <a href="https://arxiv.org/abs/2311.16498">MagicAnimate: Temporally Consistent Human Image Animation using Diffusion Model
                        </a>.<br>
                        Zhongcong Xu, Jianfeng Zhang, Jun Hao Liew, <u>Hanshu Yan</u>, Jia-Wei Liu, Chenxu Zhang, Jiashi Feng, Mike Zheng Shou <br>
                        <i>CVPR 2024</i> &nbsp; <i class="material-icons">home</i>[<a href="https://github.com/magic-research/magic-animate">Page</a>] <br>


                    </td>
                </tr>
                <tr><td><br></td></tr>

                <tr>
                    <td><img class="Image" src="assets/projects/2023_magicprop.png" width = "90%" height = "auto" /> &nbsp;&nbsp;</td>
                    <td>
                        <mark class='c0'>^</mark> <a href="https://arxiv.org/abs/2309.00908">MagicProp: Diffusion-based Video Editing via Motion-aware Appearance Propagation</a>. <br>
                        <u>Hanshu Yan</u>*, Jun Hao Liew*, Long Mai, Shanchuan Lin, Jiashi Feng <br>
                        <i>arXiv 2023</i> <br>
                    </td>
                </tr>
                <tr><td><br></td></tr>

                <tr>
                    <td><img class="Image" src="assets/projects/2023_adjointdpm.png" width = "90%" height = "auto" /> &nbsp;&nbsp;</td>
                    <td>
                        <mark class='c0'>^</mark> <a href="https://arxiv.org/abs/2307.10711">AdjointDPM: Adjoint Sensitivity Method for Gradient Backpropagation of Diffusion Probabilistic Models</a>. <br>
                        Jiachun Pan*, Jun Hao Liew, Vincent Y. F. Tan, Jiashi Feng, <u>Hanshu Yan</u>* <br>
                        <i>ICLR 2024</i> &nbsp; <i class="material-icons">home</i>[<a href="https://github.com/HanshuYAN/AdjointDPM">Page</a>] <br>
                        <mark class='c0'>^</mark> <a href="https://arxiv.org/abs/2312.12030">SAG: Towards Accurate Guided Diffusion Sampling through Symplectic Adjoint Method</a>. <br>
                        Jiachun Pan*, <u>Hanshu Yan</u>*, Jun Hao Liew, Jiashi Feng, Vincent Y. F. Tan <br>
                        <i>arXiv 2023</i> <br>
                    </td>
                </tr>
                <tr><td><br></td></tr>



                <tr>
                    <td><img class="Image" src="assets/projects/2022_magicmix.png" width = "90%" height = "auto" /> &nbsp;&nbsp;</td>
                    <td>
                        <mark class='c0'>^</mark> <a href="https://arxiv.org/abs/2210.16056">MagicMix: Semantic Mixing with Diffusion Models</a>. <br>
                        Jun Hao Liew*, <u>Hanshu Yan</u>*, Daquan Zhou, Jiashi Feng <br>
                        <i>arXiv 2022</i> <br>
                    </td>
                </tr>
                <tr><td><br></td></tr>



                <!-- Robustness -->
                <tr>
                    <td><img class="Image" src="assets/projects/2022_ijcai.png" width = "90%" height = "auto" /> &nbsp;&nbsp;</td>
                    <td>
                        <mark class='c1'>^</mark> <a href="https://arxiv.org/abs/2201.04397">Towards Adversarially Robust Deep Image Denoising</a>. <br>
                        <u>Hanshu Yan</u>, Jingfeng Zhang, Jiashi Feng, Masashi Sugiyama, Vincent Y. F. Tan  <br>
                        <i>IJCAI 2022</i> <br>
                    </td>
                </tr>

                <tr>
                    <td><img class="Image" src="assets/projects/2021_cifs.png" width = "90%" height = "auto" /> &nbsp;&nbsp;</td>
                    <td>
                        <mark class='c1'>^</mark> <a href="http://proceedings.mlr.press/v139/yan21e.html">CIFS: Improving Adversarial Robustness of CNNs via Channel-wise Importance-based Feature Selection</a>. <br>
                        <u>Hanshu Yan</u>, Jingfeng Zhang, Gang Niu, Jiashi Feng, Vincent Y. F. Tan, Masashi Sugiyama <br>
                        <i>ICML 2021</i> <br>
                    </td>
                </tr>

                <tr>
                    <td><img class="Image" src="assets/projects/2020_tisode.png" width = "90%" height = "auto" /> &nbsp;&nbsp;</td>
                    <td>
                        <mark class='c1'>^</mark> <a href="https://arxiv.org/abs/1910.05513">On Robustness of Neural Ordinary Differential Equations</a>. <br>
                        <u>Hanshu Yan</u>, Jiawei Du, Vincent Y. F. Tan, Jiashi Feng <br>
                        <i>ICLR 2020 Spotlight</i> <br>
                    </td>
                </tr>

                <!-- Learning algorithms -->
                <tr>
                    <td><img class="Image" src="assets/projects/2021_esam.png" width = "90%" height = "auto" /> &nbsp;&nbsp;</td>
                    <td>
                        <mark class='c2'>^</mark> <a href="https://arxiv.org/abs/2110.03141">Efficient Sharpness-aware Minimization for Improved Training of Neural Networks</a> .<br>
                        Jiawei Du, <u>Hanshu Yan</u>, Jiashi Feng, Joey Tianyi Zhou, Liangli Zhen, Rick Siow Mong Goh, Vincent Y. F. Tan <br>
                         <i>ICLR 2022</i> <br>
                    </td>
                </tr>

                <tr>
                    <td><img class="Image" src="assets/projects/2021_slrla.png" width = "90%" height = "auto" /> &nbsp;&nbsp;</td>
                    <td>
                        <mark class='c2'>^</mark> <a href="https://papers.nips.cc/paper/2021/hash/e53a0a2978c28872a4505bdb51db06dc-Abstract.html">Towards Understanding Why Lookahead Generalizes Better Than SGD and Beyond</a>. <br>
                        Pan Zhou, <u>Hanshu Yan</u>, Xiaotong Yuan, Jiashi Feng, Shuicheng Yan  <br>
                        <i>NeurIPS 2021</i> <br>
                    </td>
                </tr>
            
            </tbody>
            </table>




            <!-- <ul style="list-style-type: none"> -->
                <!-- Robustness -->
                <!-- <li>
                    <mark class='c1'>^</mark> <a href="https://www.sciencedirect.com/science/article/pii/S0893608023005890">Learning a robust foundation model against clean-label data poisoning attacks at downstream tasks</a>. <br>
                    Ting Zhou, Hanshu Yan*, Bo Han, Lei Liu, Jingfeng Zhang <br>
                    <i>Neural Networks 2023</i> <br>
                </li><br> -->
                <!-- <li>
                    <mark class='c1'>^</mark> <a href="https://arxiv.org/abs/2201.04397">Towards Adversarially Robust Deep Image Denoising</a>. <br>
                    Hanshu Yan, Jingfeng Zhang, Jiashi Feng, Masashi Sugiyama, Vincent Y. F. Tan  <br>
                    <i>IJCAI 2022</i> <br>
                </li><br>

                <li>
                    <mark class='c1'>^</mark> <a href="http://proceedings.mlr.press/v139/yan21e.html">CIFS: Improving Adversarial Robustness of CNNs via Channel-wise Importance-based Feature Selection</a>. <br>
                    Hanshu Yan, Jingfeng Zhang, Gang Niu, Jiashi Feng, Vincent Y. F. Tan, Masashi Sugiyama <br>
                    <i>ICML 2021</i> <br>
                </li><br>

                <li>
                    <mark class='c1'>^</mark> <a href="https://arxiv.org/pdf/2004.14798.pdf">RAIN: Robust and Accurate Classification Networks with Randomization and Enhancement</a>. <br>
                    Jiawei Du, Hanshu Yan, Joey Tianyi Zhou, Rick Siow Mong Goh, Jiashi Feng <br>
                    <i>arXiv 2020</i> <br>
                </li><br>

                <li>
                    <mark class='c1'>^</mark> <a href="https://arxiv.org/abs/1910.05513">On Robustness of Neural Ordinary Differential Equations</a>. <br>
                    Hanshu Yan, Jiawei Du, Vincent Y. F. Tan, Jiashi Feng <br>
                    <i>ICLR 2020 Spotlight</i> <br>
                </li><br> -->

                <!-- Learning algorithms -->
                <!-- <li>
                    <mark class='c2'>^</mark> <a href="https://pubs.acs.org/doi/abs/10.1021/acs.analchem.1c01559">Towards Better Time Series Contrastive Learning: A Dynamic Bad Pair Mining Approach</a>. <br>
                    Xiang Lan, Hanshu Yan, Shenda Hong, Mengling Feng <br>
                    <i>ICLR 2024</i>  <br>
                </li><br>

                <li>
                    <mark class='c2'>^</mark> <a href="https://arxiv.org/abs/2110.00926">Information-Theoretic Characterization of the Generalization Error for Iterative Semi- Supervised Learning</a>. <br>
                    Haiyun He, Hanshu Yan, Vincent Y. F. Tan <br>
                    <i>Journal of Machine Learning Research, 2022.</i>  <br>
                </li><br>

                <li>
                    <mark class='c2'>^</mark> <a href="https://arxiv.org/abs/2110.03141">Efficient Sharpness-aware Minimization for Improved Training of Neural Networks</a> .<br>
                    Jiawei Du, Hanshu Yan, Jiashi Feng, Joey Tianyi Zhou, Liangli Zhen, Rick Siow Mong Goh, Vincent Y. F. Tan <br>
                     <i>ICLR 2022</i> <br>
                </li><br>

                <li>
                    <mark class='c2'>^</mark> <a href="https://papers.nips.cc/paper/2021/hash/e53a0a2978c28872a4505bdb51db06dc-Abstract.html">Towards Understanding Why Lookahead Generalizes Better Than SGD and Beyond</a>. <br>
                    Pan Zhou, Hanshu Yan, Xiaotong Yuan, Jiashi Feng, Shuicheng Yan  <br>
                    <i>NeurIPS 2021</i> <br>
                </li><br> -->





                <!-- Others -->

                <!-- <li>
                    <mark class='c3'>^</mark> <a href="https://pubs.acs.org/doi/abs/10.1021/acs.analchem.1c01559">Deep learning-guided fiberoptic Raman spectroscopy enables real-time in vivo diagnosis and assessment of nasopharyngeal carcinoma</a>. <i>Analytical Chemistry 2021</i>  <br>
                    Chi Shu, Hanshu Yan, Wei Zheng, Kan Lin, Anne James, Selvarajan, Sathiyamoorth, Chwee Ming Lim,  Zhiwei Huang <br>
                </li><br>


                <li>
                    <mark class='c3'>^</mark> <a href="https://arxiv.org/abs/2107.02112">Recovering the Unbiased Scene Graphs from the Biased Ones</a>. <i>ACM MM 2021</i> 
                    &nbsp;[<a href="https://github.com/coldmanck/recovering-unbiased-scene-graphs">Code</a>]<br>
                    Meng-Jiun Chiou, Henghui Ding, Hanshu Yan, Changhu Wang, Roger Zimmermann, Jiashi Feng <br>
                </li><br>


                <li>
                    <mark class='c3'>^</mark> <a href="https://www.ijcai.org/proceedings/2021/0207.pdf">Modeling Trajectories with Neural Ordinary Differential Equations</a>. <i>IJCAI 2021</i> <br>
                    Yuxuan Liang, Kun Ouyang, Hanshu Yan, Yiwei Wang, Zekun Tong and Roger Zimmermann  <br>
                </li><br>


                <li>
                    <mark class='c3'>^</mark> <a href="">Adversarial Domain Adaptation with Prototype-Based Normalized Output Conditioner</a>. <i>IEEE Transactions on Image Processing 2021</i> <br>
                    Dapeng Hu, Jian Liang, Qibin Hou, Hanshu Yan, Yunpeng Chen <br>
                </li><br> -->
                
                
            <!-- </ul> -->
        </div>






        <!-- <div style="margin:30 auto;" >
            <h2><a name="service"></a>Scholarships & Awards</h2>
            <ul>
                <li>NUS Research Scholarship, 2018-2022</li>

                <li>Outstanding Graduating Student (B.Eng @ BUAA), 2015</li>
            </ul>
        </div> -->

        <!-- <div style="margin:30 auto;" >
            <h2><a name="service"></a>Coursework</h2>
            @ School
            <ul>
                <li>EE5907 Pattern Recognition; EE4603 Biomedical Imaging Systems</li>

                <li>EE5904R Neural Networks; EE6934 Deep Learning</li>

                <li>EE5137 Stochastic Processes; EE5139 Information Theory</li>

                <li>EE5101R Linear Systems; EE5103R Computer Control Systems</li>

                <li>EE5702R Advanced Power System Analysis</li>
            </ul>

            @ Home
                <ul>
                    <li>NUS, MA3209 Metric space</li>

                    <li>CMU, 36-705 Intermediate Statistics</li>

                    <li>Stanford, CS224n Natural Language Processing with Deep Learning</li>  
                </ul>
            <a href="googleae4cabe185965a36.html"><font size="6"face="arial" color="#FFFFFF">[tmp!]</font></a>
        </div> -->


    </td>

    <!-- For the purpose of adjusting margin -->
    <td id="layout-content" style="width:20%"></td>
    </tr>


</table>
</body>





</html>
